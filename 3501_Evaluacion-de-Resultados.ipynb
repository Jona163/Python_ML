{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04cd243d",
   "metadata": {},
   "source": [
    "# Evaluación de Resultados.\n",
    "\n",
    "En este Notebook se muestran técnicas para la evaluación de los resultados de una predicción con un algoritmo de Machine Learning(ML)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4acca95",
   "metadata": {},
   "source": [
    "#### Descripción\n",
    "\n",
    "NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set which are mentioned in [1]. Although, this new version of the KDD data set still suffers from some of the problems discussed by McHugh and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods.\n",
    "\n",
    "Furthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable.\n",
    "\n",
    "### Ficheros de Datos.\n",
    "\n",
    "* <span style =\"color:green\" >**KDDTrain+.ARFF:** The full NSL-KDD train set with binary labels in ARFF format.</span>\n",
    "* KDDTrain+.TXT: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format.\n",
    "* KDDTrain+_20Percent.ARFF: A 20% subset of the KDDTrain+.arff file.\n",
    "* KDDTrain+_20Percent.TXT: A 20% subset of the KDDTrain+.txt file\n",
    "* KDDTest+.ARFF: The full NSL-KDD test set with binary labels in ARFF format.\n",
    "* KDDTest+.TXT: The full NSL-KDD test set including attack-type labels and difficulty level in CSV format.\n",
    "* KDDTest-21.ARFF: A subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21.\n",
    "* KDDTest-21.TXT: A subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21.\n",
    "\n",
    "### Descarga de los ficheros de datos.\n",
    "https://www.unb.ca/cic/datasets/index.html\n",
    "\n",
    "### Referencias adicionales sobre el conjunto de datos.\n",
    "_M. Tavallaee, E. Bagheri, W. Lu, and A. Ghorbani, “A Detailed Analysis of the KDD CUP 99 Data Set,” Submitted to Second IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA), 2009._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99724df4",
   "metadata": {},
   "source": [
    "## Importar librerias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7bd325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af04bf",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845fd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path):\n",
    "    \"\"\"Lectura del DataSet NSL-KDD.\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "    attributes = [attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1712f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construccion de una funcion de particionado que realize el particionado completo\n",
    "def train_val_test_split(df, rstate=42, shuffle = True, stratify = None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "    df, test_size = 0.4, random_state = rstate, shuffle=shuffle, stratify = strat)\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "    test_set, test_size = 0.5, random_state = rstate, shuffle = shuffle, stratify=strat)\n",
    "    return(train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a969da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construccion de un PipeLine para los atributos númericos.\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy = \"median\")),\n",
    "    ('rbst_scaler',RobustScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f366be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasform para modificar únicamente las columnas categóricas.\n",
    "# y devolver un DataFrame.\n",
    "class CustomOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._oh = OneHotEncoder(sparse = False)\n",
    "        self._columns = None\n",
    "    def fit(self, X, y = None):\n",
    "        X_cat = X.select_dtypes(include = ['object'])\n",
    "        self._columns = pd.get_dummies(X_cat).columns\n",
    "        self._oh.fit(X_cat)\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        X_copy = X.copy()\n",
    "        X_cat = X_copy.select_dtypes(include = ['object'])\n",
    "        X_num = X_copy.select_dtypes(include = ['object'])\n",
    "        X_cat_oh = self._oh.transform(X_cat)\n",
    "        X_cat_oh = pd.DataFrame(X_cat_oh,\n",
    "                               columns = self._columns, \n",
    "                               index = X_copy.index)\n",
    "        X_copy.drop(list(X_cat), axis = 1, inplace = True)\n",
    "        return X_copy.join(X_cat_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24619d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformador que prepara todo el DataSet llamado PipeLine.\n",
    "# transformadores personalizados.\n",
    "class DataFramePreparer(BaseEstimator, TransformerMixin):\n",
    "    def __init__ (self):\n",
    "        self._full_pipeline = None\n",
    "        self._columns = None\n",
    "    def fit(self, X, y = None):\n",
    "        num_attribs = list(X.select_dtypes(exclude = ['object']))\n",
    "        cat_attribs = list(X.select_dtypes(include = ['object']))\n",
    "        self._full_pipeline = ColumnTransformer([\n",
    "            (\"num\", num_pipeline, num_attribs),\n",
    "            (\"cat\", CustomOneHotEncoder(), cat_attribs),\n",
    "        ])\n",
    "        self._full_pipeline.fit(X)\n",
    "        self._columns = pd.get_dummies(X).columns\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        X_copy = X.copy()\n",
    "        X_prep = self._full_pipeline.transform(X_copy)\n",
    "        return pd.DataFrame(X_prep,\n",
    "                           X_columns = self._columns,\n",
    "                           index = X_copy.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610fbe5",
   "metadata": {},
   "source": [
    "## Lectura  del DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1d94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_kdd_dataset(\"datasets/NSL-KDD/KDDTrain+.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee5b9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232.0</td>\n",
       "      <td>8153.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>remote_job</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type     service flag  src_bytes  dst_bytes land  \\\n",
       "0       0.0           tcp    ftp_data   SF      491.0        0.0    0   \n",
       "1       0.0           udp       other   SF      146.0        0.0    0   \n",
       "2       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "3       0.0           tcp        http   SF      232.0     8153.0    0   \n",
       "4       0.0           tcp        http   SF      199.0      420.0    0   \n",
       "5       0.0           tcp     private  REJ        0.0        0.0    0   \n",
       "6       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "7       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "8       0.0           tcp  remote_job   S0        0.0        0.0    0   \n",
       "9       0.0           tcp     private   S0        0.0        0.0    0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0             0.0     0.0  0.0  ...                25.0   \n",
       "1             0.0     0.0  0.0  ...                 1.0   \n",
       "2             0.0     0.0  0.0  ...                26.0   \n",
       "3             0.0     0.0  0.0  ...               255.0   \n",
       "4             0.0     0.0  0.0  ...               255.0   \n",
       "5             0.0     0.0  0.0  ...                19.0   \n",
       "6             0.0     0.0  0.0  ...                 9.0   \n",
       "7             0.0     0.0  0.0  ...                15.0   \n",
       "8             0.0     0.0  0.0  ...                23.0   \n",
       "9             0.0     0.0  0.0  ...                13.0   \n",
       "\n",
       "  dst_host_same_srv_rate  dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                   0.17                    0.03                         0.17   \n",
       "1                   0.00                    0.60                         0.88   \n",
       "2                   0.10                    0.05                         0.00   \n",
       "3                   1.00                    0.00                         0.03   \n",
       "4                   1.00                    0.00                         0.00   \n",
       "5                   0.07                    0.07                         0.00   \n",
       "6                   0.04                    0.05                         0.00   \n",
       "7                   0.06                    0.07                         0.00   \n",
       "8                   0.09                    0.05                         0.00   \n",
       "9                   0.05                    0.06                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "5                         0.00                  0.00   \n",
       "6                         0.00                  1.00   \n",
       "7                         0.00                  1.00   \n",
       "8                         0.00                  1.00   \n",
       "9                         0.00                  1.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "5                      0.00                  1.00                      1.00   \n",
       "6                      1.00                  0.00                      0.00   \n",
       "7                      1.00                  0.00                      0.00   \n",
       "8                      1.00                  0.00                      0.00   \n",
       "9                      1.00                  0.00                      0.00   \n",
       "\n",
       "     class  \n",
       "0   normal  \n",
       "1   normal  \n",
       "2  anomaly  \n",
       "3   normal  \n",
       "4   normal  \n",
       "5  anomaly  \n",
       "6  anomaly  \n",
       "7  anomaly  \n",
       "8  anomaly  \n",
       "9  anomaly  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ef38e",
   "metadata": {},
   "source": [
    "## Division del conjunto de Datos ( DataSet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05494666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División del DataSet en los diferentes SubConjuntos.\n",
    "train_set, val_set, test_set = train_val_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "670d81c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del Training Set: 75583\n",
      "Longitud de Validación de Set: 25195\n",
      "Longitud del Test Set: 25195\n"
     ]
    }
   ],
   "source": [
    "print (\"Longitud del Training Set:\", len(train_set))\n",
    "print (\"Longitud de Validación de Set:\", len(val_set))\n",
    "print(\"Longitud del Test Set:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed1ad3",
   "metadata": {},
   "source": [
    "Para cada uno de los subconjuntos, se separa las etiquetas de las caracteristicas de entrada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71eb0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de Datos general \n",
    "X_df = df.drop(\"class\", axis = 1)\n",
    "y_df = df[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a74f3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de Datos de entrenamiento.\n",
    "X_train = train_set.drop(\"class\", axis = 1)\n",
    "y_train = train_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ad4bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de validación.\n",
    "X_val = val_set.drop(\"class\", axis = 1)\n",
    "y_val = val_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f76ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de pruebas\n",
    "X_test = test_set.drop(\"class\", axis = 1)\n",
    "y_test = test_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576495b",
   "metadata": {},
   "source": [
    "## Preparación del DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb0455f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el transformador personalizado.\n",
    "data_preparer = DataFramePreparer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eaefa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFramePreparer()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar con fit el DataSet general para que adquiera todos \n",
    "# los valores posibles.\n",
    "data_preparer.fit(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bd8f3b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'X_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5497/4194078647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Transformar el subconjunto de Datos de entrenamiento.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preparer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5497/2220291678.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mX_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mX_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         return pd.DataFrame(X_prep,\n\u001b[0m\u001b[1;32m     21\u001b[0m                            \u001b[0mX_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                            index = X_copy.index)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'X_columns'"
     ]
    }
   ],
   "source": [
    "# Transformar el subconjunto de Datos de entrenamiento.\n",
    "X_train_prep = data_preparer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d81b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_prep = data_preparer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dbd638",
   "metadata": {},
   "source": [
    "## Entrenamiento de un algortimo de Regresion Logistica \n",
    "La instanciación de un algoritmo de Machine Learning utilizado Sklaern utilizando los metodo s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
